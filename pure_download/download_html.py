import os
from time import sleep
from urllib.parse import urlparse
from typing import Optional

from msxml2_util import (
    msxml2_all_headers_dict,
    msxml2_available,
    msxml2_request,
    msxml2_read_body_bytes,
    probe_remote_msxml2,
)

from download_util import (
    cookie_header_from_session,
    get_landing_and_session,
    is_dir_like,
    normalize_proxy_for_msxml2,
    sanitize_filename,
    to_double_backslash_literal,
)

def download_html_safely_msxml2(
        download_url: str,
        download_path: str,                 # â† ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ³å®š
        filename: str,                      # â† MUSTï¼ˆå¿…é ˆï¼‰ã€‚æ‹¡å¼µå­ã¯ .html ã«å¼·åˆ¶
        *,
        session=None,
        proxy: Optional[str] = None,
        connect_timeout: int = 10,
        read_timeout: int = 180,
        max_retries: int = 10,
        referer: Optional[str] = None,
        user_agent: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    ) -> str:

    if not msxml2_available():
        raise RuntimeError("MSXML2 ãƒ˜ãƒ«ãƒ‘ãŒæœªå®šç¾©ã§ã™ï¼ˆmsxml2_request/msxml2_all_headers_dict/msxml2_read_body_bytesï¼‰ã€‚")
    if not download_url:
        raise ValueError("download_url ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    if not filename or not isinstance(filename, str):
        raise ValueError("filename ã¯å¿…é ˆã§ã™ã€‚")

    file_extension = ".htlm"

    # ãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã¸ã®å¯¾å¿œ
    base = sanitize_filename(os.path.basename(filename))

    if not base.lower().endswith((file_extension)):
        base += file_extension
        
    # download_path\filename.html ã‚’ä½œæˆ
    final_path = os.path.join(download_path, base)
    os.makedirs(os.path.dirname(final_path) or ".", exist_ok=True)
    temp_path  = final_path + ".part"

    # å…±é€šãƒ˜ãƒƒãƒ€ï¼ˆåœ§ç¸®ç„¡åŠ¹åŒ–ã§ãƒã‚¤ãƒˆç¯„å›²ã®ã‚ºãƒ¬é˜²æ­¢ï¼‰
    common_headers = {
        "User-Agent": user_agent,
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9,ja;q=0.8",
        "Connection": "close",
        "Accept-Encoding": "identity",
    }
    if referer:
        common_headers["Referer"] = referer

    # Cookie ã‚’ session ã‹ã‚‰ä»˜ä¸
    cookie_hdr = cookie_header_from_session(session, download_url)
    if cookie_hdr:
        common_headers["Cookie"] = cookie_hdr

    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆmsï¼‰
    tms = (connect_timeout * 1000, connect_timeout * 1000, read_timeout * 1000, read_timeout * 1000)
    pxy = normalize_proxy_for_msxml2(proxy)

    # ---- æœ¬ä½“ï¼ˆMSXML2, é2xxã§ .error.html é€€é¿ï¼‰----
    for attempt in range(1, max_retries + 1):
        try:
            print(f"[{attempt}/{max_retries} PROXY={pxy or 'NONE'}] GET {download_url} (HTML, MSXML2)")
            http = msxml2_request("GET", download_url, dict(common_headers), tms, pxy)
            status = int(http.status)

            if status in (418, 429):
                raise RuntimeError(f"{status} (temporary block)")
            if status < 200 or status >= 300:
                try:
                    with open(final_path + ".error.html", "w", encoding="utf-8", newline="") as ef:
                        ef.write(getattr(http, "responseText", "") or "")
                except Exception:
                    pass
                raise RuntimeError(f"HTTP {status}")

            html_text = http.responseText
            with open(temp_path, "w", encoding="utf-8", newline="") as f:
                f.write(html_text or "")
            os.replace(temp_path, final_path)
            print(f"âœ… HTML ä¿å­˜ â†’ {final_path}")
            return file_extension

        except Exception as e:
            print(f"âš ï¸ å¤±æ•— ({attempt}/{max_retries}) MSXML2: {e}")
            if attempt < max_retries:
                sleep(min(2 * attempt, 10))
                continue

    raise RuntimeError("HTMLã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# ============== å®Ÿè¡Œéƒ¨ ==============
if __name__ == "__main__":
    # download_url = "https://www.3gpp.org/ftp"
    download_url = "https://mentor.ieee.org/802.11"
    download_path = to_double_backslash_literal(r'C:\Users\yohei\Downloads')

    # --- (F) HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³æº–å‚™ï¼ˆ3GPP FTP / Cookieå–å¾—ï¼‰ ---
    LANDING, sess = get_landing_and_session("IEEE")

    try:
        ext = download_html_safely_msxml2(
            download_url,
            download_path,              # ãƒ•ã‚©ãƒ«ãƒ€ or ãƒ•ãƒ«ãƒ‘ã‚¹ã©ã¡ã‚‰ã§ã‚‚OK
            "ieee",
            session=sess,               # â˜… Cookie ã‚’è‡ªå‹•ã§ä»˜ä¸
            referer=LANDING,            # â˜… Referer ã‚‚ä»˜ä¸
            # proxy="http://proxy.example.com:8080",  # å¿…è¦ãªã‚‰
            connect_timeout=10,
            read_timeout=180,
            max_retries=5,
            )
            
        print(f"ğŸ“ æ‹¡å¼µå­: {ext or '(ä¸æ˜)'}")
    except Exception as e:
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")
        raise
